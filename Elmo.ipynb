{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOThWxrF6DWvWzLxDF4D91/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aN2umKweDps2","executionInfo":{"status":"ok","timestamp":1728238815908,"user_tz":300,"elapsed":32900,"user":{"displayName":"abhirupees 10","userId":"11832824637122382515"}},"outputId":"a015b46c-1c52-478b-bef0-fb54cbee728e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word embeddings for word WATCH in first sentence\n","[ 0.1407964  -0.1578854  -0.00950453 ...  0.4300598  -0.52887106\n","  0.06327865]\n","Word embeddings for word WATCH in second sentence\n","[-0.0821335   0.01050324 -0.0145415  ...  0.48705408 -0.54457945\n","  0.52623975]\n"]}],"source":["# import necessary libraries\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import numpy as np\n","\n","# Disable eager execution\n","tf.compat.v1.disable_eager_execution()\n","\n","# Load pre-trained ELMo model\n","elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n","\n","# Create an instance of ELMo\n","def elmo_vectors(x):\n","  # Access the 'default' signature and get the 'elmo' output\n","  embeddings = elmo.signatures['default'](tf.constant(x))['elmo']\n","  # Create a session to evaluate the embeddings\n","  with tf.compat.v1.Session() as sess:\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    return sess.run(embeddings)\n","\n","embeddings = elmo_vectors(\n","    [\n","        \"I love to watch TV\",\n","        \"I am wearing a wrist watch\"\n","    ]\n",")\n","\n","# Print word embeddings for word WATCH in given two sentences\n","print('Word embeddings for word WATCH in first sentence')\n","print(embeddings[0][3])\n","print('Word embeddings for word WATCH in second sentence')\n","print(embeddings[1][5])"]},{"cell_type":"code","source":["# prompt: What else can you demonstrate with help of the above used model (Elmo)? (keep it lowkey)\n","\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import numpy as np\n","\n","# Disable eager execution\n","tf.compat.v1.disable_eager_execution()\n","\n","# Load pre-trained ELMo model\n","elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n","\n","\n","# Create an instance of ELMo\n","def elmo_vectors(x):\n","  # Access the 'default' signature and get the 'elmo' output\n","  embeddings = elmo.signatures['default'](tf.constant(x))['elmo']\n","  # Create a session to evaluate the embeddings\n","  with tf.compat.v1.Session() as sess:\n","    sess.run(tf.compat.v1.global_variables_initializer())\n","    return sess.run(embeddings)\n","\n","# Example demonstrating sentence similarity using cosine similarity\n","sentences = [\n","    \"The cat sat on the mat.\",\n","    \"A feline was resting on a rug.\"\n","]\n","\n","embeddings = elmo_vectors(sentences)\n","\n","def cosine_similarity(vec1, vec2):\n","  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","\n","# Calculate the average embedding for each sentence\n","sentence_embeddings = [np.mean(embedding, axis=0) for embedding in embeddings]\n","\n","similarity = cosine_similarity(sentence_embeddings[0], sentence_embeddings[1])\n","print(f\"Cosine similarity between the sentences: {similarity}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEyuZGBDDu8X","executionInfo":{"status":"ok","timestamp":1728247725069,"user_tz":300,"elapsed":31919,"user":{"displayName":"abhirupees 10","userId":"11832824637122382515"}},"outputId":"897f5021-a306-4ad7-cd0b-8456acf6cb9d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cosine similarity between the sentences: 0.7657053470611572\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gnCiJIXglut-"},"execution_count":null,"outputs":[]}]}